{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW14_1101180418_RNN100.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmFHCJKdzrBkZFaHtNDbCf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cimelmeli/Neural-Network-model/blob/main/HW14_1101180418_RNN100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3VZGI65yE8T",
        "outputId": "75bdefa8-731e-4f3e-934f-e8d541711020"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2zvGik_dRmu",
        "outputId": "1dc34fe9-e637-40ad-b5ac-e0a241af2c3b"
      },
      "source": [
        "cd/content/drive/MyDrive/HW14_AI & Bigdata\n"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/HW14_AI & Bigdata\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_dvYI2tdMVl"
      },
      "source": [
        "# Original code is from https://github.com/spro/practical-pytorch\n",
        "import time\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from name_dataset import NameDataset\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzenUizpbkJi",
        "outputId": "04a7ed20-f27e-4cb2-a1bb-92a5c68728b8"
      },
      "source": [
        "HIDDEN_SIZE = 100\n",
        "N_LAYERS = 2\n",
        "BATCH_SIZE = 256\n",
        "N_EPOCHS = 25\n",
        "\n",
        "test_dataset = NameDataset(is_train_set=False)\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "                         batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "\n",
        "train_dataset = NameDataset(is_train_set=True)\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "N_COUNTRIES = len(train_dataset.get_countries())\n",
        "print(N_COUNTRIES, \"countries\")\n",
        "N_CHARS = 128  # ASCII"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18 countries\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy4LbHZ5fLZr"
      },
      "source": [
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def create_variable(tensor):\n",
        "    # Do cuda() before wrapping with variable\n",
        "    if torch.cuda.is_available():\n",
        "        return Variable(tensor.cuda())\n",
        "    else:\n",
        "        return Variable(tensor)\n"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKsR0DCXfN80"
      },
      "source": [
        ""
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TluWtO-MfOGg"
      },
      "source": [
        "def pad_sequences(vectorized_seqs, seq_lengths, countries):\n",
        "    seq_tensor = torch.zeros((len(vectorized_seqs), seq_lengths.max())).long()\n",
        "    for idx, (seq, seq_len) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
        "        seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
        "\n",
        "    # Sort tensors by their length\n",
        "    seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
        "    seq_tensor = seq_tensor[perm_idx]\n",
        "\n",
        "    # Also sort the target (countries) in the same order\n",
        "    target = countries2tensor(countries)\n",
        "    if len(countries):\n",
        "        target = target[perm_idx]\n",
        "        \n",
        "    # Return variables\n",
        "    # DataParallel requires everything to be a Variable\n",
        "    return create_variable(seq_tensor), \\\n",
        "        create_variable(seq_lengths), \\\n",
        "        create_variable(target)\n",
        "        "
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCJHGpB5fZJN"
      },
      "source": [
        "def make_variables(names, countries):\n",
        "    sequence_and_length = [str2ascii_arr(name) for name in names]\n",
        "    vectorized_seqs = [sl[0] for sl in sequence_and_length]\n",
        "    seq_lengths = torch.LongTensor([sl[1] for sl in sequence_and_length])\n",
        "    return pad_sequences(vectorized_seqs, seq_lengths, countries)\n",
        "\n",
        "\n",
        "def str2ascii_arr(msg):\n",
        "    arr = [ord(c) for c in msg]\n",
        "    return arr, len(arr)\n",
        "\n",
        "\n",
        "def countries2tensor(countries):\n",
        "    country_ids = [train_dataset.get_country_id(\n",
        "        country) for country in countries]\n",
        "    return torch.LongTensor(country_ids)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCNyUT3Al49s"
      },
      "source": [
        ""
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FjbQ9kXl7d6"
      },
      "source": [
        ""
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4zdPEaal_sU"
      },
      "source": [
        "class RNNClassifier(nn.Module):\n",
        "    # Our model\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True):\n",
        "        super(RNNClassifier, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.n_directions = int(bidirectional) + 1\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.rnn = nn.RNN(hidden_size, hidden_size, n_layers,\n",
        "                          bidirectional=bidirectional)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input, seq_lengths):\n",
        "        # Note: we run this all at once (over the whole input sequence)\n",
        "        # input shape: B x S (input size)\n",
        "        # transpose to make S(sequence) x B (batch)\n",
        "        input = input.t()\n",
        "        batch_size = input.size(1)\n",
        "\n",
        "        # Make a hidden\n",
        "        hidden = self._init_hidden(batch_size)\n",
        "\n",
        "        # Embedding S x B -> S x B x I (embedding size)\n",
        "        embedded = self.embedding(input)\n",
        "\n",
        "        # Pack them up nicely\n",
        "        rnn_input = pack_padded_sequence(\n",
        "            embedded, seq_lengths.data.cpu().numpy())\n",
        "\n",
        "        # To compact weights again call flatten_parameters().\n",
        "        self.rnn.flatten_parameters()\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "        # Use the last layer output as FC's input\n",
        "        # No need to unpack, since we are going to use hidden\n",
        "        fc_output = self.fc(hidden[-1])\n",
        "        return fc_output\n",
        "\n",
        "    def _init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.n_layers * self.n_directions,\n",
        "                             batch_size, self.hidden_size)\n",
        "        return create_variable(hidden)\n",
        "        "
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCRpBrIhrTwt",
        "outputId": "fcfe7620-87a3-461a-a176-2e4292464d14"
      },
      "source": [
        "# Train cycle\n",
        "def train():\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, (names, countries) in enumerate(train_loader, 1):\n",
        "        input, seq_lengths, target = make_variables(names, countries)\n",
        "        output = classifier(input, seq_lengths)\n",
        "\n",
        "        loss = criterion(output, target)\n",
        "        total_loss += loss.data\n",
        "\n",
        "        classifier.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print('[{}] Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.2f}'.format(\n",
        "                time_since(start), epoch,  i *\n",
        "                len(names), len(train_loader.dataset),\n",
        "                100. * i * len(names) / len(train_loader.dataset),\n",
        "                total_loss / i * len(names)))\n",
        "\n",
        "    return total_loss\n",
        "\n",
        "# Testing cycle\n",
        "def test(name=None):\n",
        "    # Predict for a given name\n",
        "    if name:\n",
        "        input, seq_lengths, target = make_variables([name], [])\n",
        "        output = classifier(input, seq_lengths)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        country_id = pred.cpu().numpy()[0][0]\n",
        "        print(name, \"is\", train_dataset.get_country(country_id))\n",
        "        return\n",
        "\n",
        "    print(\"evaluating trained model ...\")\n",
        "    correct = 0\n",
        "    train_data_size = len(test_loader.dataset)\n",
        "\n",
        "    for names, countries in test_loader:\n",
        "        input, seq_lengths, target = make_variables(names, countries)\n",
        "        output = classifier(input, seq_lengths)\n",
        "        pred = output.data.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        correct, train_data_size, 100. * correct / train_data_size))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_COUNTRIES, N_LAYERS)\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "        # dim = 0 [33, xxx] -> [11, ...], [11, ...], [11, ...] on 3 GPUs\n",
        "        classifier = nn.DataParallel(classifier)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        classifier.cuda()\n",
        "\n",
        "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    start = time.time()\n",
        "    print(\"Training for %d epochs...\" % N_EPOCHS)\n",
        "    for epoch in range(1, N_EPOCHS + 1):\n",
        "        # Train cycle\n",
        "        train()\n",
        "\n",
        "        # Testing\n",
        "        test()\n",
        "\n",
        "        # Testing several samples\n",
        "        test(\"Sung\")\n",
        "        test(\"Jungwoo\")\n",
        "        test(\"Soojin\")\n",
        "        test(\"Nako\")"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 25 epochs...\n",
            "[0m 0s] Train Epoch: 1 [2560/13374 (19%)]\tLoss: 590.32\n",
            "[0m 1s] Train Epoch: 1 [5120/13374 (38%)]\tLoss: 520.30\n",
            "[0m 2s] Train Epoch: 1 [7680/13374 (57%)]\tLoss: 493.95\n",
            "[0m 3s] Train Epoch: 1 [10240/13374 (77%)]\tLoss: 474.91\n",
            "[0m 3s] Train Epoch: 1 [12800/13374 (96%)]\tLoss: 462.39\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 3961/6700 (59%)\n",
            "\n",
            "Sung is English\n",
            "Jungwoo is Russian\n",
            "Soojin is Russian\n",
            "Nako is Russian\n",
            "[0m 5s] Train Epoch: 2 [2560/13374 (19%)]\tLoss: 349.89\n",
            "[0m 5s] Train Epoch: 2 [5120/13374 (38%)]\tLoss: 330.54\n",
            "[0m 6s] Train Epoch: 2 [7680/13374 (57%)]\tLoss: 319.00\n",
            "[0m 7s] Train Epoch: 2 [10240/13374 (77%)]\tLoss: 311.24\n",
            "[0m 7s] Train Epoch: 2 [12800/13374 (96%)]\tLoss: 305.12\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 4615/6700 (69%)\n",
            "\n",
            "Sung is English\n",
            "Jungwoo is Japanese\n",
            "Soojin is Russian\n",
            "Nako is Arabic\n",
            "[0m 9s] Train Epoch: 3 [2560/13374 (19%)]\tLoss: 256.92\n",
            "[0m 9s] Train Epoch: 3 [5120/13374 (38%)]\tLoss: 254.88\n",
            "[0m 10s] Train Epoch: 3 [7680/13374 (57%)]\tLoss: 254.21\n",
            "[0m 11s] Train Epoch: 3 [10240/13374 (77%)]\tLoss: 254.16\n",
            "[0m 11s] Train Epoch: 3 [12800/13374 (96%)]\tLoss: 252.81\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 4876/6700 (73%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[0m 13s] Train Epoch: 4 [2560/13374 (19%)]\tLoss: 239.32\n",
            "[0m 13s] Train Epoch: 4 [5120/13374 (38%)]\tLoss: 235.60\n",
            "[0m 14s] Train Epoch: 4 [7680/13374 (57%)]\tLoss: 230.09\n",
            "[0m 15s] Train Epoch: 4 [10240/13374 (77%)]\tLoss: 226.98\n",
            "[0m 16s] Train Epoch: 4 [12800/13374 (96%)]\tLoss: 224.20\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5088/6700 (76%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[0m 17s] Train Epoch: 5 [2560/13374 (19%)]\tLoss: 207.33\n",
            "[0m 18s] Train Epoch: 5 [5120/13374 (38%)]\tLoss: 201.88\n",
            "[0m 18s] Train Epoch: 5 [7680/13374 (57%)]\tLoss: 198.11\n",
            "[0m 19s] Train Epoch: 5 [10240/13374 (77%)]\tLoss: 197.18\n",
            "[0m 20s] Train Epoch: 5 [12800/13374 (96%)]\tLoss: 196.16\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5221/6700 (78%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[0m 21s] Train Epoch: 6 [2560/13374 (19%)]\tLoss: 176.77\n",
            "[0m 22s] Train Epoch: 6 [5120/13374 (38%)]\tLoss: 179.86\n",
            "[0m 22s] Train Epoch: 6 [7680/13374 (57%)]\tLoss: 177.16\n",
            "[0m 23s] Train Epoch: 6 [10240/13374 (77%)]\tLoss: 176.93\n",
            "[0m 24s] Train Epoch: 6 [12800/13374 (96%)]\tLoss: 177.25\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5246/6700 (78%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[0m 25s] Train Epoch: 7 [2560/13374 (19%)]\tLoss: 169.82\n",
            "[0m 26s] Train Epoch: 7 [5120/13374 (38%)]\tLoss: 166.71\n",
            "[0m 26s] Train Epoch: 7 [7680/13374 (57%)]\tLoss: 166.59\n",
            "[0m 27s] Train Epoch: 7 [10240/13374 (77%)]\tLoss: 164.50\n",
            "[0m 28s] Train Epoch: 7 [12800/13374 (96%)]\tLoss: 162.74\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5289/6700 (79%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[0m 29s] Train Epoch: 8 [2560/13374 (19%)]\tLoss: 153.06\n",
            "[0m 30s] Train Epoch: 8 [5120/13374 (38%)]\tLoss: 148.66\n",
            "[0m 31s] Train Epoch: 8 [7680/13374 (57%)]\tLoss: 153.56\n",
            "[0m 31s] Train Epoch: 8 [10240/13374 (77%)]\tLoss: 151.70\n",
            "[0m 32s] Train Epoch: 8 [12800/13374 (96%)]\tLoss: 150.52\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5325/6700 (79%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[0m 33s] Train Epoch: 9 [2560/13374 (19%)]\tLoss: 141.12\n",
            "[0m 34s] Train Epoch: 9 [5120/13374 (38%)]\tLoss: 138.27\n",
            "[0m 35s] Train Epoch: 9 [7680/13374 (57%)]\tLoss: 138.11\n",
            "[0m 35s] Train Epoch: 9 [10240/13374 (77%)]\tLoss: 138.30\n",
            "[0m 36s] Train Epoch: 9 [12800/13374 (96%)]\tLoss: 138.88\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5441/6700 (81%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[0m 37s] Train Epoch: 10 [2560/13374 (19%)]\tLoss: 132.97\n",
            "[0m 38s] Train Epoch: 10 [5120/13374 (38%)]\tLoss: 129.56\n",
            "[0m 39s] Train Epoch: 10 [7680/13374 (57%)]\tLoss: 132.09\n",
            "[0m 39s] Train Epoch: 10 [10240/13374 (77%)]\tLoss: 131.83\n",
            "[0m 40s] Train Epoch: 10 [12800/13374 (96%)]\tLoss: 131.48\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5481/6700 (82%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[0m 41s] Train Epoch: 11 [2560/13374 (19%)]\tLoss: 118.27\n",
            "[0m 42s] Train Epoch: 11 [5120/13374 (38%)]\tLoss: 120.26\n",
            "[0m 43s] Train Epoch: 11 [7680/13374 (57%)]\tLoss: 120.02\n",
            "[0m 43s] Train Epoch: 11 [10240/13374 (77%)]\tLoss: 120.91\n",
            "[0m 44s] Train Epoch: 11 [12800/13374 (96%)]\tLoss: 121.66\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5488/6700 (82%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Russian\n",
            "[0m 45s] Train Epoch: 12 [2560/13374 (19%)]\tLoss: 122.68\n",
            "[0m 46s] Train Epoch: 12 [5120/13374 (38%)]\tLoss: 118.44\n",
            "[0m 47s] Train Epoch: 12 [7680/13374 (57%)]\tLoss: 115.87\n",
            "[0m 47s] Train Epoch: 12 [10240/13374 (77%)]\tLoss: 115.69\n",
            "[0m 48s] Train Epoch: 12 [12800/13374 (96%)]\tLoss: 116.34\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5474/6700 (82%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is English\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[0m 49s] Train Epoch: 13 [2560/13374 (19%)]\tLoss: 109.70\n",
            "[0m 50s] Train Epoch: 13 [5120/13374 (38%)]\tLoss: 105.41\n",
            "[0m 51s] Train Epoch: 13 [7680/13374 (57%)]\tLoss: 105.85\n",
            "[0m 51s] Train Epoch: 13 [10240/13374 (77%)]\tLoss: 105.75\n",
            "[0m 52s] Train Epoch: 13 [12800/13374 (96%)]\tLoss: 106.77\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5516/6700 (82%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is English\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[0m 53s] Train Epoch: 14 [2560/13374 (19%)]\tLoss: 99.45\n",
            "[0m 54s] Train Epoch: 14 [5120/13374 (38%)]\tLoss: 99.25\n",
            "[0m 55s] Train Epoch: 14 [7680/13374 (57%)]\tLoss: 97.32\n",
            "[0m 56s] Train Epoch: 14 [10240/13374 (77%)]\tLoss: 99.30\n",
            "[0m 56s] Train Epoch: 14 [12800/13374 (96%)]\tLoss: 101.24\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5476/6700 (82%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is English\n",
            "Soojin is Irish\n",
            "Nako is Japanese\n",
            "[0m 58s] Train Epoch: 15 [2560/13374 (19%)]\tLoss: 101.88\n",
            "[0m 58s] Train Epoch: 15 [5120/13374 (38%)]\tLoss: 96.53\n",
            "[0m 59s] Train Epoch: 15 [7680/13374 (57%)]\tLoss: 95.76\n",
            "[1m 0s] Train Epoch: 15 [10240/13374 (77%)]\tLoss: 97.47\n",
            "[1m 0s] Train Epoch: 15 [12800/13374 (96%)]\tLoss: 97.24\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5558/6700 (83%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[1m 2s] Train Epoch: 16 [2560/13374 (19%)]\tLoss: 85.45\n",
            "[1m 2s] Train Epoch: 16 [5120/13374 (38%)]\tLoss: 86.78\n",
            "[1m 3s] Train Epoch: 16 [7680/13374 (57%)]\tLoss: 87.28\n",
            "[1m 4s] Train Epoch: 16 [10240/13374 (77%)]\tLoss: 87.51\n",
            "[1m 4s] Train Epoch: 16 [12800/13374 (96%)]\tLoss: 88.42\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5527/6700 (82%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[1m 6s] Train Epoch: 17 [2560/13374 (19%)]\tLoss: 80.70\n",
            "[1m 6s] Train Epoch: 17 [5120/13374 (38%)]\tLoss: 83.83\n",
            "[1m 7s] Train Epoch: 17 [7680/13374 (57%)]\tLoss: 83.54\n",
            "[1m 8s] Train Epoch: 17 [10240/13374 (77%)]\tLoss: 83.03\n",
            "[1m 8s] Train Epoch: 17 [12800/13374 (96%)]\tLoss: 83.23\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5538/6700 (83%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[1m 10s] Train Epoch: 18 [2560/13374 (19%)]\tLoss: 80.15\n",
            "[1m 10s] Train Epoch: 18 [5120/13374 (38%)]\tLoss: 79.63\n",
            "[1m 11s] Train Epoch: 18 [7680/13374 (57%)]\tLoss: 78.37\n",
            "[1m 12s] Train Epoch: 18 [10240/13374 (77%)]\tLoss: 78.01\n",
            "[1m 12s] Train Epoch: 18 [12800/13374 (96%)]\tLoss: 78.15\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5550/6700 (83%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is English\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[1m 14s] Train Epoch: 19 [2560/13374 (19%)]\tLoss: 73.11\n",
            "[1m 14s] Train Epoch: 19 [5120/13374 (38%)]\tLoss: 75.48\n",
            "[1m 15s] Train Epoch: 19 [7680/13374 (57%)]\tLoss: 74.89\n",
            "[1m 16s] Train Epoch: 19 [10240/13374 (77%)]\tLoss: 74.55\n",
            "[1m 16s] Train Epoch: 19 [12800/13374 (96%)]\tLoss: 74.01\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5562/6700 (83%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Russian\n",
            "[1m 18s] Train Epoch: 20 [2560/13374 (19%)]\tLoss: 70.78\n",
            "[1m 18s] Train Epoch: 20 [5120/13374 (38%)]\tLoss: 67.22\n",
            "[1m 19s] Train Epoch: 20 [7680/13374 (57%)]\tLoss: 68.88\n",
            "[1m 20s] Train Epoch: 20 [10240/13374 (77%)]\tLoss: 68.90\n",
            "[1m 20s] Train Epoch: 20 [12800/13374 (96%)]\tLoss: 70.22\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5540/6700 (83%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is English\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[1m 22s] Train Epoch: 21 [2560/13374 (19%)]\tLoss: 68.12\n",
            "[1m 22s] Train Epoch: 21 [5120/13374 (38%)]\tLoss: 67.05\n",
            "[1m 23s] Train Epoch: 21 [7680/13374 (57%)]\tLoss: 66.13\n",
            "[1m 24s] Train Epoch: 21 [10240/13374 (77%)]\tLoss: 66.74\n",
            "[1m 24s] Train Epoch: 21 [12800/13374 (96%)]\tLoss: 66.12\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5563/6700 (83%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[1m 26s] Train Epoch: 22 [2560/13374 (19%)]\tLoss: 61.49\n",
            "[1m 27s] Train Epoch: 22 [5120/13374 (38%)]\tLoss: 59.14\n",
            "[1m 27s] Train Epoch: 22 [7680/13374 (57%)]\tLoss: 59.54\n",
            "[1m 28s] Train Epoch: 22 [10240/13374 (77%)]\tLoss: 58.98\n",
            "[1m 29s] Train Epoch: 22 [12800/13374 (96%)]\tLoss: 59.38\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5563/6700 (83%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is English\n",
            "Soojin is Irish\n",
            "Nako is Japanese\n",
            "[1m 30s] Train Epoch: 23 [2560/13374 (19%)]\tLoss: 48.77\n",
            "[1m 31s] Train Epoch: 23 [5120/13374 (38%)]\tLoss: 50.46\n",
            "[1m 31s] Train Epoch: 23 [7680/13374 (57%)]\tLoss: 51.40\n",
            "[1m 32s] Train Epoch: 23 [10240/13374 (77%)]\tLoss: 52.98\n",
            "[1m 33s] Train Epoch: 23 [12800/13374 (96%)]\tLoss: 54.37\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5533/6700 (83%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[1m 34s] Train Epoch: 24 [2560/13374 (19%)]\tLoss: 54.66\n",
            "[1m 35s] Train Epoch: 24 [5120/13374 (38%)]\tLoss: 54.28\n",
            "[1m 35s] Train Epoch: 24 [7680/13374 (57%)]\tLoss: 53.29\n",
            "[1m 36s] Train Epoch: 24 [10240/13374 (77%)]\tLoss: 53.73\n",
            "[1m 37s] Train Epoch: 24 [12800/13374 (96%)]\tLoss: 53.98\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5567/6700 (83%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is Chinese\n",
            "Soojin is Czech\n",
            "Nako is Japanese\n",
            "[1m 38s] Train Epoch: 25 [2560/13374 (19%)]\tLoss: 51.26\n",
            "[1m 39s] Train Epoch: 25 [5120/13374 (38%)]\tLoss: 51.48\n",
            "[1m 39s] Train Epoch: 25 [7680/13374 (57%)]\tLoss: 52.36\n",
            "[1m 40s] Train Epoch: 25 [10240/13374 (77%)]\tLoss: 52.68\n",
            "[1m 41s] Train Epoch: 25 [12800/13374 (96%)]\tLoss: 52.85\n",
            "evaluating trained model ...\n",
            "\n",
            "Test set: Accuracy: 5506/6700 (82%)\n",
            "\n",
            "Sung is Chinese\n",
            "Jungwoo is English\n",
            "Soojin is Czech\n",
            "Nako is Russian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnVTeyY6mTDy"
      },
      "source": [
        ""
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPjdpYabmUyu"
      },
      "source": [
        ""
      ],
      "execution_count": 109,
      "outputs": []
    }
  ]
}